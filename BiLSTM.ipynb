{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are trying to reproduce [the paper](https://pdfs.semanticscholar.org/edff/b62b32ffcc2b5cc846e26375cb300fac9ecc.pdf) for speaker change detection\n",
    "\n",
    "## Review\n",
    "\n",
    "**Sequence Labelling** \n",
    "\n",
    "They think this task as a binary classification. Thus, they label changing frame as a **1** and non-changing frame as a **0**. So that, they use the _binary cross-entropy loss function_.\n",
    "\n",
    "**Network Architecture**\n",
    "- 2 Bi-LSTM\n",
    "    - 64 and 32 outputs respectively.\n",
    "- Multi Layer Perceptron\n",
    "    - 3 Fully Connected Feedforward Layers\n",
    "        - 40, 20, 1 dimensional respectively.\n",
    "    - Tanh activation for first 2 layer\n",
    "    - Sigmoid activation for last layer\n",
    "    \n",
    "**Feature Extraction**\n",
    "- \"35-dimensional acoustic features are extracted every 16ms on a 32ms window using [Yaafe toolkit](http://yaafe.sourceforge.net).\"\n",
    "    - 11 Mel-Frequency Cepstral Coefficients (MFCC), \n",
    "    - Their first and second derivatives,\n",
    "    - First and second derivatives of the energy.\n",
    "\n",
    "**Class Imbalance**\n",
    "\n",
    "- _\"The number of positive labels isincreased artificially by labeling as positive every frame in the direct neighborhood of the manually annotated change point.\"_\n",
    "- A positive neighborhood of 100ms (50ms on both sides) is used around each change point, to partially solve the class imbalance problem.\n",
    "\n",
    "**Subsequences**\n",
    "\n",
    "- _\"The long audio sequences are split into short fixed-length overlapping sequences.\"_\n",
    "\n",
    "**Prediction**\n",
    "\n",
    "- _\"Finally, local score maxima exceeding a pre-determined threshold Î¸ are marked as speaker change points.\"_\n",
    "\n",
    "**Training**\n",
    "\n",
    "- Subsequences for training are 3.2s long with a step of 800ms (i.e. two adjacent sequences overlap by 75%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "We will use Yaafe Toolkit. (To see all available features, you can use _!yaafe -l_) To learn how we can do that, start with http://yaafe.github.io/Yaafe/manual/quickstart.html#quick-start-using-yaafe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can view a description of each feature (or output format) with the -d option:\n",
    "\n",
    "!yaafe -d MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yaafe -d Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine blockSize and stepSize. \n",
    "\n",
    "If we have 16kHz audio signal(in AMI, we have 16kHz), for 32 ms block, we need 16x32, For the stepsize as 16 ms, we need 16x16 size.\n",
    "\n",
    "We need these features:\n",
    "\n",
    "- mfcc: MFCC blockSize=512 stepSize=256 CepsNbCoeffs=11\n",
    "- mfcc_d1: MFCC blockSize=512 stepSize=256 CepsNbCoeffs=11 > Derivate DOrder=1\n",
    "- mfcc_d2: MFCC blockSize=512 stepSize=256 CepsNbCoeffs=11 > Derivate DOrder=2\n",
    "- energy_d1: Energy blockSize=512 stepSize=256  > Derivate DOrder=1\n",
    "- energy_d2: Energy blockSize=512 stepSize=256  > Derivate DOrder=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract all of these, we will use [this technique](http://yaafe.github.io/Yaafe/manual/quickstart.html#extract-several-features). Shortly, we will write all these features into single text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"featureplan.txt\", \"w\")\n",
    "f.write(\"mfcc: MFCC blockSize=512 stepSize=256 CepsNbCoeffs=11 \\n\"\n",
    "        \"mfcc_d1: MFCC blockSize=512 stepSize=256 CepsNbCoeffs=11 > Derivate DOrder=1 \\n\"\n",
    "        \"mfcc_d2: MFCC blockSize=512 stepSize=256 CepsNbCoeffs=11 > Derivate DOrder=2 \\n\"\n",
    "        \"energy_d1: Energy blockSize=512 stepSize=256  > Derivate DOrder=1 \\n\"\n",
    "        \"energy_d2: Energy blockSize=512 stepSize=256  > Derivate DOrder=2\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat featureplan.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yaafe -c featureplan.txt -r 16000 a2002011001-e02-16kHz.wav -p Precision=8 -p Metadata=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Librosa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def wav_to_matrix(filename, hop, win_len): # hop and win_len in milisecond \n",
    "    audio, sr = librosa.load(filename)\n",
    "    # https://github.com/librosa/librosa/issues/584\n",
    "    mfccs = librosa.feature.mfcc(audio, sr, n_mfcc=11, hop_length=int(float(hop/1000)*sr), n_fft=int(float(win_len/1000)*sr))\n",
    "    mfccs_d1 = librosa.feature.delta(mfccs)\n",
    "    mfccs_d2 = librosa.feature.delta(mfccs, order=2)\n",
    "    energy = librosa.feature.rmse(y=audio, hop_length=int(float(hop/1000)*sr), frame_length=int(float(win_len/1000)*sr))\n",
    "    energy_d1 = librosa.feature.delta(energy)\n",
    "    energy_d2 = librosa.feature.delta(energy, order=2)\n",
    "    print (mfccs.shape)\n",
    "    print (mfccs_d1.shape)\n",
    "    print (mfccs_d2.shape)\n",
    "    print (energy_d1.shape)\n",
    "    print (energy_d2.shape)\n",
    "\n",
    "    a = np.vstack((mfccs, mfccs_d1, mfccs_d2, energy_d1, energy_d2))\n",
    "    # line_mfccs = np.ravel(mfccs, order='F')\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def create_data_for_supervised(root_dir, hop, win_len):\n",
    "    all_audio_paths = glob.glob(os.path.join(root_dir, '*wav'))\n",
    "    matrix_of_all_audio = []\n",
    "    \n",
    "    output_array = []\n",
    "    \n",
    "    for single_audio_path in all_audio_paths:\n",
    "        end_time_array_second = []\n",
    "\n",
    "        filename = (single_audio_path.split(\"/\")[-1]).split(\".\")[0]\n",
    "        matrix_of_single_audio = wav_to_matrix(single_audio_path, hop, win_len)\n",
    "        array_of_single_audio = np.ravel(matrix_of_single_audio)\n",
    "        \n",
    "        if (matrix_of_single_audio is not None):\n",
    "            \n",
    "            print (matrix_of_single_audio.shape)\n",
    "            matrix_of_all_audio.extend(array_of_single_audio)\n",
    "            print (single_audio_path + \" is done.\")\n",
    "            \n",
    "            main_set = \"./txt_files/\" + filename + \"_end_time.txt\"# FILENAME PATH for TXT\n",
    "            \n",
    "            with open(main_set) as f:\n",
    "                content = f.readlines()\n",
    "                \n",
    "            # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "            \n",
    "                    \n",
    "            # need to open text file\n",
    "            # after that, point the end point of speaker\n",
    "            # add 1 to point of speaker, add 0 otherwise\n",
    "            # time is in second format at the txt file\n",
    "            content = [x.strip() for x in content] \n",
    "\n",
    "            for single_line in content:\n",
    "            \n",
    "                end_time_array_second.append(single_line)\n",
    "                \n",
    "                # we use following method to get milisecond version\n",
    "                # float(win_len + ((offset+100) * hop)) \n",
    "                # we need to inversion of that\n",
    "                \n",
    "            output_array = np.zeros(matrix_of_single_audio.shape[1])\n",
    "            \n",
    "            for end_time in end_time_array_second:\n",
    "                end_time_ms = float(end_time)*1000\n",
    "                which_start_hop = (end_time_ms-win_len)/hop # now we know, milisecond version of change\n",
    "                                            # which is located after which_hop paramater\n",
    "                                            # add 2 and round to up\n",
    "                which_end_hop = end_time_ms/hop # round to up\n",
    "\n",
    "                start_location = math.ceil(which_start_hop + 2)\n",
    "                end_location = math.ceil(which_end_hop)\n",
    "\n",
    "                output_array[start_location:end_location+1] = 1.0\n",
    "\n",
    "            print (output_array)\n",
    "            print (output_array.mean())\n",
    "            ar = np.arange(matrix_of_single_audio.shape[1]) # just as an example array\n",
    "            pp.plot(ar, output_array, 'x')\n",
    "            pp.show()\n",
    "                \n",
    "            \n",
    "    audio_array = np.asarray(matrix_of_all_audio)\n",
    "    audio_array = np.reshape(matrix_of_all_audio, (35,-1))\n",
    "   \n",
    "        \n",
    "    input_array = np.asarray(audio_array)\n",
    "    input_array = input_array.reshape((len(input_array), np.prod(input_array.shape[1:])))  \n",
    "    print(input_array.shape)\n",
    "    \n",
    "    output_array = np.asarray(output_array)\n",
    "    print(output_array.shape)\n",
    "\n",
    "    return (input_array, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 154884)\n",
      "(11, 154884)\n",
      "(11, 154884)\n",
      "(1, 154884)\n",
      "(1, 154884)\n",
      "(35, 154884)\n",
      "./amicorpus/IN1002/audio/IN1002.Mix-Headset.wav is done.\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.00424188424886\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 164018)\n",
      "(11, 164018)\n",
      "(11, 164018)\n",
      "(1, 164018)\n",
      "(1, 164018)\n",
      "(35, 164018)\n",
      "./amicorpus/IS1000d/audio/IS1000d.Mix-Headset.wav is done.\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.00573717518809\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d8777f9e5bd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_for_supervised\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"./amicorpus/*/audio/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-37279fc6ce6f>\u001b[0m in \u001b[0;36mcreate_data_for_supervised\u001b[0;34m(root_dir, hop, win_len)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msingle_audio_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmatrix_of_single_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_audio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0marray_of_single_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_of_single_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f42077d85f01>\u001b[0m in \u001b[0;36mwav_to_matrix\u001b[0;34m(filename, hop, win_len)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwav_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# hop and win_len in milisecond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# https://github.com/librosa/librosa/issues/584\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmfccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhop\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_len\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyannote/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyannote/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyannote/lib/python3.6/site-packages/resampy/core.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inn, out = create_data_for_supervised (\"./amicorpus/*/audio/\", 16, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/herdogan/Desktop/SpChangeDetect\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 32806)\n",
      "(11, 32806)\n",
      "(11, 32806)\n",
      "(1, 32806)\n",
      "(1, 32806)\n"
     ]
    }
   ],
   "source": [
    "k = wav_to_matrix(\"How to Read a Research Paper.mp3\", 16, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 32806)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 16380)\n",
      "(11, 16380)\n",
      "(11, 16380)\n",
      "(1, 16380)\n",
      "(1, 16380)\n"
     ]
    }
   ],
   "source": [
    "k = wav_to_matrix(\"How to Read a Research Paper.mp3\", 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "%matplotlib inline\n",
    "\n",
    "pp.plot(np.swapaxes(k, 0, 1))\n",
    "pp.axhline(y=0.5, color='r', linestyle='-')\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Subsequences with Label\n",
    "\n",
    "At that point, we should create training and test data with their label. Also, we can use directly [pyannote.metrics](https://github.com/pyannote/pyannote-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Architecture\n",
    "\n",
    "We can directly upload the model's architecture from the .yml file which is provided by writer.\n",
    "\n",
    "However, I want to directly write all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author's .yml files\n",
    "\n",
    "!wget https://raw.githubusercontent.com/yinruiqing/change_detection/master/model/architecture.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load to model\n",
    "\n",
    "from keras.models import model_from_yaml\n",
    "yaml_file = open('architecture.yml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "frame_shape = (320, 35)\n",
    "\n",
    "## Network Architecture\n",
    "\n",
    "input_frame = keras.Input(frame_shape, name='main_input')\n",
    "\n",
    "bidirectional_1 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(input_frame)\n",
    "bidirectional_2 = layers.Bidirectional(layers.LSTM(40, activation='tanh', return_sequences=True))(bidirectional_1)\n",
    "\n",
    "tdistributed_1 = layers.TimeDistributed(layers.Dense(40, activation='tanh'))(bidirectional_2)\n",
    "tdistributed_2 = layers.TimeDistributed(layers.Dense(20, activation='tanh'))(tdistributed_1)\n",
    "tdistributed_3 = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(tdistributed_2)\n",
    "\n",
    "## Source: https://stackoverflow.com/questions/37743574/hard-limiting-threshold-activation-function-in-tensorflow\n",
    "def step_activation(x):\n",
    "    threshold = 0.4\n",
    "    cond = tf.less(x, tf.fill(value=threshold, dims=tf.shape(x)))\n",
    "    out = tf.where(cond, tf.zeros(tf.shape(x)), tf.ones(tf.shape(x)))\n",
    "\n",
    "    return out\n",
    "\n",
    "step_activation = layers.Dense(1, activation=step_activation, name='threshold_activation')(tdistributed_3)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(input_frame, step_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save our model\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To look our model\n",
    "\n",
    "!cat model.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
